{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ca0ca2",
   "metadata": {
    "id": "a6ca0ca2"
   },
   "source": [
    "# 주제분석 2주차 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a956d0",
   "metadata": {
    "id": "b9a956d0"
   },
   "source": [
    "## Chaper 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756312c0",
   "metadata": {
    "id": "756312c0"
   },
   "source": [
    "### 문제0. 기본세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd95bee",
   "metadata": {
    "id": "7dd95bee"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pathlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b550c",
   "metadata": {
    "id": "5e2b550c"
   },
   "source": [
    "### 문제1. 시드설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70406797",
   "metadata": {
    "id": "70406797"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(17)\n",
    "seed = np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18976220",
   "metadata": {
    "id": "18976220"
   },
   "source": [
    "### 문제2. dog, cat 변수를 만들어 폴더에 들어있는 경로들을 리스트 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ZjDrgEA91Kik",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjDrgEA91Kik",
    "outputId": "384608b0-863d-4d76-eec4-9bbaf78b3b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f9e16b",
   "metadata": {
    "id": "f5f9e16b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cat_dir = pathlib.Path('/content/gdrive/My Drive/training_set/cats')\n",
    "dog_dir = pathlib.Path('/content/gdrive/My Drive/training_set/dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2700096b",
   "metadata": {
    "id": "2700096b"
   },
   "outputs": [],
   "source": [
    "cat = []\n",
    "for i in cat_dir.iterdir():\n",
    "    cat.append(i)\n",
    "    \n",
    "dog = []\n",
    "for i in dog_dir.iterdir():\n",
    "    dog.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce94803",
   "metadata": {
    "id": "9ce94803"
   },
   "source": [
    "### 문제3. 저장한 리스트를 8:2로 나누고 train/test로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22be87e8",
   "metadata": {
    "id": "22be87e8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_train, cat_val = train_test_split(cat, test_size = 0.2, shuffle = True, random_state = seed)\n",
    "dog_train, dog_val = train_test_split(dog, test_size = 0.2, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d243a103",
   "metadata": {
    "id": "d243a103"
   },
   "outputs": [],
   "source": [
    "train = cat_train + dog_train\n",
    "val = cat_val + dog_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dc48f",
   "metadata": {
    "id": "2f2dc48f"
   },
   "source": [
    "### 문제4. torchvision.transforms를 이용하여 이미지 데이터 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d22de",
   "metadata": {
    "id": "1a2d22de"
   },
   "source": [
    "### 4-1. train 데이터셋 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab751c77",
   "metadata": {
    "id": "ab751c77"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128,128)), #사이즈 조정\n",
    "    transforms.RandomHorizontalFlip(), #이미지를 수직변환할 수 있게 하여 방향변화에 robust한 형태로 만들기\n",
    "    transforms.ToTensor() #PIL 형태의 이미지나 ndarray 를 PyTorch 가 이해할 수 있는 tensor 자료형으로 바꾸어 주는 역할\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4e87c",
   "metadata": {
    "id": "4eb4e87c"
   },
   "source": [
    "### 4-2. val 데이터셋 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002740c7",
   "metadata": {
    "id": "002740c7"
   },
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf1daf",
   "metadata": {
    "id": "acaf1daf"
   },
   "source": [
    "### 문제5. Dataset class 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3469cc89",
   "metadata": {
    "id": "3469cc89"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#데이터의 양이 방대할 경우, 데이터를 한번에 불러오기 어렵기 때문에, 하나씩 불러서 쓰는 방식을 택하기 위해 Dcustomized된 ataset을 사용함\n",
    "#미니배치 학습, 데이터 셔플, 병렬 처리까지 간단하게 수행\n",
    "\n",
    "class Dataset(Dataset) :\n",
    "    \n",
    "    def __init__(self, data, transforms): #생성될 때 한번만 실행됨\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self): #데이터의 개수 \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index): #인덱스값을 기준으로 데이터셋에서 sample을 가져오고, 이를 변환하는 과정을 거침\n",
    "        image_path = self.data[index]\n",
    "        image = PIL.Image.open(image_path)\n",
    "        image_transformed = self.transforms(image)\n",
    "        \n",
    "        if \"cat\" in str(self.data[index]) :\n",
    "            label = 0\n",
    "        else :\n",
    "            label = 1\n",
    "            \n",
    "        return image_transformed, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad13c7a",
   "metadata": {
    "id": "5ad13c7a"
   },
   "source": [
    "### 6. 만든 Dataset class를 이용하여 train, val 데이터를 Dataset 형식으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6906b3",
   "metadata": {
    "id": "6c6906b3"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data = train, transforms = train_transforms)\n",
    "val_dataset = Dataset(data = val, transforms = val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e7937d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1e7937d",
    "outputId": "824d9d86-9f55-4d41-947d-0d3dca4f29b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6404 1601\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e3136b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4e3136b",
    "outputId": "7d0d953d-19b7-4726-a615-acce4bff740a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6392, 0.6353, 0.6275,  ..., 0.7412, 0.7412, 0.7490],\n",
       "          [0.6392, 0.6392, 0.6235,  ..., 0.7294, 0.7294, 0.7373],\n",
       "          [0.6353, 0.6314, 0.6275,  ..., 0.7137, 0.7176, 0.7216],\n",
       "          ...,\n",
       "          [0.6314, 0.6078, 0.6000,  ..., 0.6510, 0.5608, 0.5294],\n",
       "          [0.6196, 0.6078, 0.6039,  ..., 0.7020, 0.6000, 0.5608],\n",
       "          [0.6039, 0.5961, 0.5922,  ..., 0.7333, 0.5922, 0.5490]],\n",
       " \n",
       "         [[0.5804, 0.5765, 0.5686,  ..., 0.7059, 0.7059, 0.7137],\n",
       "          [0.5804, 0.5804, 0.5647,  ..., 0.6980, 0.6980, 0.7059],\n",
       "          [0.5765, 0.5725, 0.5686,  ..., 0.6824, 0.6863, 0.6902],\n",
       "          ...,\n",
       "          [0.6039, 0.5804, 0.5725,  ..., 0.6235, 0.5373, 0.5059],\n",
       "          [0.5922, 0.5804, 0.5765,  ..., 0.6745, 0.5725, 0.5333],\n",
       "          [0.5765, 0.5686, 0.5647,  ..., 0.7059, 0.5647, 0.5216]],\n",
       " \n",
       "         [[0.5608, 0.5569, 0.5490,  ..., 0.7098, 0.7098, 0.7137],\n",
       "          [0.5608, 0.5608, 0.5451,  ..., 0.6941, 0.6941, 0.6980],\n",
       "          [0.5569, 0.5529, 0.5490,  ..., 0.6706, 0.6706, 0.6784],\n",
       "          ...,\n",
       "          [0.5686, 0.5490, 0.5529,  ..., 0.6510, 0.5529, 0.5137],\n",
       "          [0.5529, 0.5529, 0.5529,  ..., 0.7255, 0.6118, 0.5608],\n",
       "          [0.5373, 0.5294, 0.5294,  ..., 0.7647, 0.5961, 0.5373]]]), 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ad6eb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24ad6eb0",
    "outputId": "83a5f525-40da-4c3f-ef81-a1eb54704e99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6471, 0.6314, 0.5020,  ..., 0.7098, 0.8039, 0.8588],\n",
       "          [0.6510, 0.6431, 0.5569,  ..., 0.6588, 0.6902, 0.7373],\n",
       "          [0.6314, 0.6196, 0.5804,  ..., 0.6902, 0.7490, 0.7294],\n",
       "          ...,\n",
       "          [0.7725, 0.7608, 0.7647,  ..., 0.7490, 0.7451, 0.7412],\n",
       "          [0.7843, 0.7647, 0.7804,  ..., 0.7529, 0.7255, 0.7255],\n",
       "          [0.7765, 0.7608, 0.7647,  ..., 0.7529, 0.7412, 0.7373]],\n",
       " \n",
       "         [[0.6235, 0.6196, 0.4627,  ..., 0.6196, 0.7608, 0.8275],\n",
       "          [0.6235, 0.6275, 0.5216,  ..., 0.5647, 0.6157, 0.6745],\n",
       "          [0.6039, 0.6078, 0.5569,  ..., 0.6118, 0.6588, 0.6392],\n",
       "          ...,\n",
       "          [0.7451, 0.7294, 0.7333,  ..., 0.7176, 0.7137, 0.7098],\n",
       "          [0.7529, 0.7333, 0.7490,  ..., 0.7216, 0.6941, 0.6941],\n",
       "          [0.7451, 0.7294, 0.7333,  ..., 0.7176, 0.7098, 0.7059]],\n",
       " \n",
       "         [[0.5961, 0.5216, 0.3098,  ..., 0.4392, 0.5529, 0.6314],\n",
       "          [0.5922, 0.5373, 0.3882,  ..., 0.4118, 0.4275, 0.4667],\n",
       "          [0.5647, 0.5255, 0.4549,  ..., 0.4980, 0.5020, 0.4549],\n",
       "          ...,\n",
       "          [0.7294, 0.7176, 0.7176,  ..., 0.7098, 0.7059, 0.7020],\n",
       "          [0.7451, 0.7255, 0.7373,  ..., 0.7137, 0.6863, 0.6863],\n",
       "          [0.7373, 0.7216, 0.7255,  ..., 0.7176, 0.7059, 0.6980]]]), 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b79b1c",
   "metadata": {
    "id": "24b79b1c"
   },
   "source": [
    "### 7. Dataset을 Dataloader로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb831fc",
   "metadata": {
    "id": "eeb831fc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#batch형태로 만들어서 우리가 실제로 학습할 때 이용할 수 있게 형태를 만들어주는 라이브러리 : DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a016010f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a016010f",
    "outputId": "336d0e03-f5f2-4550-d9e2-6c872c663191"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f49d7b16690>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1832654",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1832654",
    "outputId": "d3877c7a-712d-455c-fa14-d3504ad7934c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f49d7b16750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1620c0",
   "metadata": {
    "id": "ea1620c0"
   },
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75d1eb",
   "metadata": {
    "id": "1d75d1eb"
   },
   "source": [
    "### 1. CNN 모델을 class 형태로 만들어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40726ad2",
   "metadata": {
    "id": "40726ad2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() ## 기반 class를 초기화하고, 해당 class 속성을 subclass가 스스로 받아오도록 함!\n",
    "        \n",
    "        ### Conv2d -> BathNorm -> ReLU -> Maxpool\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3), ###in_channels) 흑백이면 1, RGB면 3\n",
    "            nn.BatchNorm2d(16),\n",
    "            ### batch정규화 : 각 배치 단위 별로 데이터가 다양한 분포를 가지더라도 각 배치별로 평균과 분산을 이용해 정규화\n",
    "            ### batch parameter의 기준은 input size\n",
    "            nn.ReLU(),\n",
    "            ### 양수면 자기자신, 음수면 0을 반환 / 갈수록 기울기가 소실되는 시그모이드 개선(0~1사이의 값만 내보냄)\n",
    "            ### 가중치 업데이트 속도, 연산 속도가 매우 빠르고(함수가 간단), 기울기 소실(vanishing Gradient)문제가 발생하지 않음\n",
    "            ### feature가 발현될 가능성을 비선형적 그래프로 나타내주는 작업이 필요(non-linearity 부여)\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            ### pooling은 파라미터를 줄여 overfitting을 방지하고, 속도를 높이기 위한 방법\n",
    "            ### convolution layer를 resize하여 새로운 layer를 얻는 것, 특징을 뽑아내는 작업\n",
    "        )    \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))        \n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))        \n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.fc = nn.Linear(1024,2) #평탄화 작업, Convolution/Pooling 프로세스의 결과를 취하여 다음 결과와 이어질 수 있게 연결하는 역할\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        \n",
    "        x = x.reshape(-1,1024)\n",
    "        \n",
    "        x = self.fc(x) ### fc layer를 거친 값으로 반환\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f3ce9",
   "metadata": {
    "id": "410f3ce9"
   },
   "source": [
    "### 2. 그래픽카드로 장치 설정 후, 모델 그래픽 카드에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b943a038",
   "metadata": {
    "id": "b943a038"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b774f30",
   "metadata": {
    "id": "5b774f30"
   },
   "source": [
    "### 3. optimizer와 loss function 정의(모델 학습을 위해 최적화, 손실 함수가 필요함!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918806c5",
   "metadata": {
    "id": "918806c5"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) #learniing rate 설정\n",
    "### Adam : 모멘텀 최적화 + RMSProp / 모멘텀 최적화처럼 Gradient Descent을 따르고, RMSProp처럼 그레디언트 제곱의 지수 감소 평균을 따름\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "### softmax(classification score을 0~1 사이로 정규화, 모든 합이 1) + crossentropy\n",
    "### 정답 class에 해당하는 값에 대해서만 log 합 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61010f86",
   "metadata": {
    "id": "61010f86"
   },
   "source": [
    "### 4. 2중 for문을 이용한 모델 학습, iteration 100번 지날 때마다 loss 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1ebe4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d1ebe4a",
    "outputId": "6a99b07c-712e-4b91-f12d-2a249c5a57fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 loss:  0.414\n",
      "Epoch : 2 loss:  0.467\n",
      "Epoch : 3 loss:  0.306\n",
      "Epoch : 4 loss:  0.249\n",
      "Epoch : 5 loss:  0.287\n",
      "Epoch : 6 loss:  0.260\n",
      "Epoch : 7 loss:  0.296\n",
      "Epoch : 8 loss:  0.210\n",
      "Epoch : 9 loss:  0.196\n",
      "Epoch : 10 loss:  0.073\n",
      "Epoch : 11 loss:  0.132\n",
      "Epoch : 12 loss:  0.120\n",
      "Epoch : 13 loss:  0.102\n",
      "Epoch : 14 loss:  0.066\n",
      "Epoch : 15 loss:  0.159\n",
      "Epoch : 16 loss:  0.061\n",
      "Epoch : 17 loss:  0.018\n",
      "Epoch : 18 loss:  0.012\n",
      "Epoch : 19 loss:  0.011\n",
      "Epoch : 20 loss:  0.025\n",
      "Epoch : 21 loss:  0.035\n",
      "Epoch : 22 loss:  0.018\n",
      "Epoch : 23 loss:  0.054\n",
      "Epoch : 24 loss:  0.075\n",
      "Epoch : 25 loss:  0.023\n",
      "Epoch : 26 loss:  0.011\n",
      "Epoch : 27 loss:  0.004\n",
      "Epoch : 28 loss:  0.001\n",
      "Epoch : 29 loss:  0.015\n",
      "Epoch : 30 loss:  0.006\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 30\n",
    "\n",
    "for epoch in range(num_epoch) :\n",
    "  ### enumerate : index와 원소로 이루어진 tuple 생성 (index와 원소에 동시 접근해서 loop를 돌릴 수 있음)\n",
    "  for index, data in enumerate(train_dataloader) :\n",
    "    input, label = data\n",
    "    input, label = input.to(device), label.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(input)\n",
    "    \n",
    "    loss = loss_function(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if index % 100 == 99:\n",
    "      print(f'Epoch : {epoch + 1} loss: {loss.item() : .3f}')\n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "puQG6YkZrAGh",
   "metadata": {
    "id": "puQG6YkZrAGh"
   },
   "source": [
    "### 5. 평가모드로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "KeBi-EoykTd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeBi-EoykTd2",
    "outputId": "8b2b9738-9ebd-4ebc-f6fb-756cc084fdce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() ##해당 모델의 모든 layer가 eval모드에 적용됨, Dropout이나 Batchnorm 비활성화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AAWAroXNr-CV",
   "metadata": {
    "id": "AAWAroXNr-CV"
   },
   "source": [
    "### 6. Train Accuracy 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "s6IyHZDTr9sX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6IyHZDTr9sX",
    "outputId": "4b69de55-7eaa-4def-fdd2-ad4d716c7837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data: 100.0%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input,label in train_dataloader:\n",
    "        x = input.to(device)\n",
    "        y= label.to(device)\n",
    "\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        # torch.max함수는 (최댓값,index)를 반환 \n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        # 전체 개수 += 라벨의 개수\n",
    "        total += label.size(0)\n",
    "        \n",
    "        # 도출한 모델의 index와 라벨이 일치하면 correct에 개수 추가\n",
    "        correct += (output_index == y).sum().float()\n",
    "    \n",
    "    # 정확도 도출\n",
    "    print(\"Accuracy of Train Data: {}%\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1iqH__12UbB1",
   "metadata": {
    "id": "1iqH__12UbB1"
   },
   "source": [
    "### 7. Validation Accuracy 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "h8PNedQWUZSE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8PNedQWUZSE",
    "outputId": "f21c0479-5a2a-4a48-8e09-94e8ad6c2ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Validation Data: 89.06932830810547%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "mis_predicted_value = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input,label in val_dataloader:\n",
    "        x = input.to(device)\n",
    "        y= label.to(device)\n",
    "\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        # torch.max함수는 (최댓값,index)를 반환 \n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        # 전체 개수 += 라벨의 개수\n",
    "        total += label.size(0)\n",
    "        \n",
    "        # 도출한 모델의 index와 라벨이 일치하면 correct에 개수 추가\n",
    "        correct += (output_index == y).sum().float()\n",
    "\n",
    "        # mispredict값 관련\n",
    "        for mispredict in range(len(output_index != label)) :\n",
    "            if mispredict == True :\n",
    "                mis_predicted_value.append([data[0][mispredict], data[1][mispredict]])\n",
    "\n",
    "    # 정확도 도출\n",
    "    print(\"Accuracy of Validation Data: {}%\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Z5ptaUYfWWU",
   "metadata": {
    "id": "6Z5ptaUYfWWU"
   },
   "source": [
    "### 8. 잘못 예측한 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9y73vRa1sk9u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y73vRa1sk9u",
    "outputId": "868a3cc9-593e-44f3-d6b3-0140d4a2daa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5098, 0.5333, 0.5059,  ..., 0.5137, 0.4549, 0.4549],\n",
       "         [0.4902, 0.5216, 0.4784,  ..., 0.5451, 0.4824, 0.4078],\n",
       "         [0.5373, 0.5176, 0.5255,  ..., 0.5922, 0.4431, 0.2745],\n",
       "         ...,\n",
       "         [0.4784, 0.5294, 0.4706,  ..., 0.4431, 0.4235, 0.3490],\n",
       "         [0.4902, 0.4902, 0.3882,  ..., 0.4784, 0.4235, 0.5020],\n",
       "         [0.5804, 0.5451, 0.3412,  ..., 0.4667, 0.5412, 0.6118]],\n",
       "\n",
       "        [[0.5686, 0.5922, 0.5608,  ..., 0.4510, 0.3725, 0.3804],\n",
       "         [0.5373, 0.5686, 0.5294,  ..., 0.4980, 0.4196, 0.3686],\n",
       "         [0.5686, 0.5569, 0.5686,  ..., 0.5647, 0.3961, 0.2314],\n",
       "         ...,\n",
       "         [0.5176, 0.4745, 0.4039,  ..., 0.4824, 0.4941, 0.4039],\n",
       "         [0.4980, 0.4863, 0.3961,  ..., 0.5137, 0.4941, 0.5412],\n",
       "         [0.5686, 0.5725, 0.3961,  ..., 0.5059, 0.5961, 0.6314]],\n",
       "\n",
       "        [[0.3529, 0.3804, 0.3569,  ..., 0.4510, 0.3725, 0.3490],\n",
       "         [0.3647, 0.3843, 0.3294,  ..., 0.4824, 0.4157, 0.3647],\n",
       "         [0.4314, 0.3961, 0.3765,  ..., 0.5176, 0.3765, 0.2078],\n",
       "         ...,\n",
       "         [0.3137, 0.2941, 0.2471,  ..., 0.3098, 0.2745, 0.2078],\n",
       "         [0.3451, 0.2980, 0.2039,  ..., 0.3294, 0.2627, 0.3686],\n",
       "         [0.4431, 0.3922, 0.1843,  ..., 0.3137, 0.3804, 0.5059]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_predicted_value[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wa9wWOyCoggU",
   "metadata": {
    "id": "Wa9wWOyCoggU"
   },
   "source": [
    "### 9. Torch vision의 models에서 pretrained된 resnet34 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "TL5e-1YWomjU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TL5e-1YWomjU",
    "outputId": "c3dddaa0-a7c1-4b74-b901-45e8285c625c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet34 = models.resnet34(pretrained = True)\n",
    "print(resnet34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wxjAFdkBoyXN",
   "metadata": {
    "id": "wxjAFdkBoyXN"
   },
   "source": [
    "### 10. 불러온 모델의 fc layer를 문제에 맞게 바꾸어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "JJmYsz31o4_b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJmYsz31o4_b",
    "outputId": "6d43d2cd-f318-4f2c-ef70-1ea52da06828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### pretrained된 딥러닝 모델을 binary classification에 사용하기\n",
    "\n",
    "nr_filters = resnet34.fc.in_features  # number of input features of last layer\n",
    "resnet34.fc = nn.Linear(nr_filters, 2) # binary classification -> 2\n",
    "\n",
    "resnet34.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AI4dZ6dZvUuv",
   "metadata": {
    "id": "AI4dZ6dZvUuv"
   },
   "source": [
    "### 11. Fine-tuning과 transfer learning의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "THPgfUCBvW2B",
   "metadata": {
    "id": "THPgfUCBvW2B"
   },
   "source": [
    "transfer learning 방법 중 하나가 fine tuning이다.\n",
    "\n",
    "- transfer learning : pretrained 모델을 가져와 분석자가 가진 데이터셋으로 재학습시키는 과정.\n",
    "- fine tuning : pretrained 모델을 가져와 분석자가 가진 데이터셋으로 재학습 시키는 것에 더하여, 분석 목적에 맞게 모델 architecture를 변형한다! ex) 범주분류의 개수를 줄이거나, 출력층을 목적에 맞게 변형시키는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mTAhKvPywCGR",
   "metadata": {
    "id": "mTAhKvPywCGR"
   },
   "source": [
    "### 12. 불러온 모델을 train data로 학습시키기! epoch은 10회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hDwyXChUvUfg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDwyXChUvUfg",
    "outputId": "23d4c8bb-b844-4209-c76f-b99f922526b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 loss:  0.003\n",
      "Epoch : 2 loss:  0.001\n",
      "Epoch : 3 loss:  0.001\n",
      "Epoch : 4 loss:  0.003\n",
      "Epoch : 5 loss:  0.002\n",
      "Epoch : 6 loss:  0.003\n",
      "Epoch : 7 loss:  0.003\n",
      "Epoch : 8 loss:  0.002\n",
      "Epoch : 9 loss:  0.003\n",
      "Epoch : 10 loss:  0.001\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(resnet34.parameters(), lr = 0.001) #learniing rate 설정\n",
    "### Adam : 모멘텀 최적화 + RMSProp / 모멘텀 최적화처럼 Gradient Descent을 따르고, RMSProp처럼 그레디언트 제곱의 지수 감소 평균을 따름\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "### softmax(classification score을 0~1 사이로 정규화, 모든 합이 1) + crossentropy\n",
    "### 정답 class에 해당하는 값에 대해서만 log 합 진\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "for epoch in range(num_epoch) :\n",
    "  ### enumerate : index와 원소로 이루어진 tuple 생성 (index와 원소에 동시 접근해서 loop를 돌릴 수 있음)\n",
    "  for index, data in enumerate(train_dataloader) :\n",
    "    input, label = data\n",
    "    input, label = input.to(device), label.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(input)\n",
    "    \n",
    "    loss = loss_function(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if index % 100 == 99:\n",
    "      print(f'Epoch : {epoch + 1} loss: {loss.item() : .3f}')\n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvvTISkRwmDb",
   "metadata": {
    "id": "OvvTISkRwmDb"
   },
   "source": [
    "### 13. 모델을 평가모델로 바꾼 후, train accuracy와 validation accuracy 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "rY4-ik3pwsK2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY4-ik3pwsK2",
    "outputId": "8617a4b2-32ec-4e28-d5ef-7dd3ae0b58ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet34.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56AzpuLSwtLo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56AzpuLSwtLo",
    "outputId": "f4287b3d-5712-4561-8917-e4bdc9609a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data: 49.96876907348633%\n"
     ]
    }
   ],
   "source": [
    "### train accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input,label in train_dataloader:\n",
    "        x = input.to(device)\n",
    "        y= label.to(device)\n",
    "\n",
    "        output = resnet34.forward(x)\n",
    "        \n",
    "        # torch.max함수는 (최댓값,index)를 반환 \n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        # 전체 개수 += 라벨의 개수\n",
    "        total += label.size(0)\n",
    "        \n",
    "        # 도출한 모델의 index와 라벨이 일치하면 correct에 개수 추가\n",
    "        correct += (output_index == y).sum().float()\n",
    "    \n",
    "    # 정확도 도출\n",
    "    print(\"Accuracy of Train Data: {}%\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7Qrc25ySwtJe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Qrc25ySwtJe",
    "outputId": "453fbb55-f114-4b4f-d57d-7665042cffad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Validation Data: 49.96876907348633%\n"
     ]
    }
   ],
   "source": [
    "### validation accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input,label in val_dataloader:\n",
    "        x = input.to(device)\n",
    "        y= label.to(device)\n",
    "\n",
    "        output = resnet34.forward(x)\n",
    "        \n",
    "        # torch.max함수는 (최댓값,index)를 반환 \n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        # 전체 개수 += 라벨의 개수\n",
    "        total += label.size(0)\n",
    "        \n",
    "        # 도출한 모델의 index와 라벨이 일치하면 correct에 개수 추가\n",
    "        correct += (output_index == y).sum().float()\n",
    "\n",
    "    # 정확도 도출\n",
    "    print(\"Accuracy of Validation Data: {}%\".format(100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "주제분석 2주차 패키지.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
