---
title: "2week"
author: "Jongseok Yu"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. 전처리
##### 1-0. 기본세팅
```{r}
setwd("C:/Users/yjs49/Desktop/2week_package")

options(warn = -1)
library(tidyverse)
library(data.table)
library(magrittr)
library(lubridate)

train <- fread("train.csv")
stores <- fread("stores.csv")
oil <- fread("oil.csv")
holidays<-fread("holidays_events.csv")
```

##### 1-1. 데이터 파악
```{r}
str(train)
str(stores)
str(oil)
str(holidays)
```
##### 1-2. Holidays data 전처리
```{r}
holidays <- holidays[!(holidays$transferred == TRUE)]
holidays <- rename(holidays, "holiday" = "type")
holidays <- holidays[,c(1,2)]
```

##### 1-3. 데이터프레임 합치기
```{r}
dfs <- list(train, oil, holidays)

data <- dfs %>%
  plyr::join_all(by="date", match="first") %>%
  left_join(stores, by="store_nbr")
```

```{r}
nrow(train)
```

```{r}
nrow(data)
```

```{r}
sum(is.na(c(data$id,data$date,data$store_nbr,data$family,data$sales,data$onpromotion)))
```

```{r}
oil[is.na(oil$dcoilwtico)][,date]
```

```{r}
data[is.na(data$dcoilwtico)][,date] %>%
  unique()
```


```{r}
anti_join(data, oil, by="date")[,date] %>%
  wday(label=TRUE) %>%
  unique()
```


```{r}
data %<>%
  mutate(holiday = ifelse(is.na(holiday),0,1))
```


```{r}
data %>%
  count(holiday)
```

##### 1-4. data 누락 날짜 확인
```{r}
unique(data$date)
```


```{r}
date = seq(as.Date("2014-07-01"), as.Date("2017-08-15"), by="day")
date[! date %in% unique(data$date)]
```

##### 1-5. train data와 test data 분리
```{r}
train_set <- data[data$date <= as.Date(max(data$date))-15]
test_set <- data[data$date > as.Date(max(data$date))-15]
```

##### 1-6. 파생변수 생성
```{r}
train_set %<>%
  mutate(wday = wday(date, label = TRUE),
         year = year(date),
         month = month(date))
```

##### 1-7. 판매량이 0인 날이 많은 store 확인
```{r}
train_set %>%
  group_by(date, store_nbr) %>%
  summarize(day_sales = sum(sales)) %>%
  group_by(store_nbr) %>%
  mutate(zero_sales = ifelse(day_sales == 0, 1, 0)) %>%
  summarize(zero_days = sum(zero_sales) / n()) %>% #왜 n()으로 나눴는데 결과가 잘 나오는지는 의문...
  arrange(desc(zero_days))
```


```{r}
train_set %>%
  group_by(date,store_nbr) %>%
  summarize(count = n()) %>% #33
  group_by(store_nbr) %>%
  summarize(count = n()) #1124
```
###### 하나의 store별로 계산기록이 37092개 존재, date별로 보면 한 store당 33개의 데이터 존재 -> date를 기준으로 store_nbr를 계산하면 1124개가 나옴!

##### 1-8. 판매량 작은 store 시각화, 해당 row 제거
```{r}
train_set %>%
  filter(store_nbr %in% c(52,22,42,21,29,20,18)) %>%
  ggplot(aes(x = date, y = sales))+
  geom_line(color = "skyblue")+
  facet_wrap(~ store_nbr, scales = "free", nrow = 3)+
  theme_classic()

# geom_bar, stat="identity"와 geom_col은 같은 역할을 수행함!
```


```{r}
train_set <- train_set[!(train_set$store_nbr %in% c(52,22,42,21,29,20,18)),]
unique(train_set$store_nbr)
```

##### 1-9. family 분포 살피기, 10%이상인 row 제거
```{r}
train_set %>%
  group_by(date, family) %>%
  summarize(total_sales = sum(sales)) %>%
  group_by(family) %>%
  mutate(zero_sales = ifelse(total_sales == 0, 1, 0)) %>%
  summarize(zero_family = sum(zero_sales) / n()) %>%
  arrange(zero_family)
```


```{r}
family_list <- unique(train_set[(train_set$family %in% c('MAGAZINES','HOME CARE','PET SUPPLIES','CELEBRATION','PLAYERS AND ELECTRONICS','LADIESWEAR','SCHOOL AND OFFICE SUPPLIES','BABY CARE','BOOKS'))][,4])

train_set <- train_set[!(train_set$family %in% c('MAGAZINES','HOME CARE','PET SUPPLIES','CELEBRATION','PLAYERS AND ELECTRONICS','LADIESWEAR','SCHOOL AND OFFICE SUPPLIES','BABY CARE','BOOKS'))]
```

##### 1-10. 범주형 변수로 변환
```{r}
train_set[,c('store_nbr','family', 'holiday','city','state','type','cluster','wday','year','month')] = lapply((train_set[,c('store_nbr','family', 'holiday', 'city','state','type','cluster','wday','year','month')]), as.factor)

str(train_set)
```

### 2. NA imputation
##### 2-1. 데이터프레임 생성, 중복 제거
```{r}
df1 <- data.frame(date = train_set[,date], dcoilwtico = train_set[,dcoilwtico]) %>%
  unique()
```

##### 2-2. NA는 전날의 oil price로 대체 (시계열데이터)
```{r}
which(is.na(df1$dcoilwtico))

for (i in which(is.na(df1$dcoilwtico))){
  df1$dcoilwtico[i] <- df1$dcoilwtico[i-1]
}

# which로 index값 얻고, 이 index값을 가질 떄 inpute하자는 아이디어
```

##### 2-3. oil_price 변수로 결합
```{r}
train_set %<>%
  merge(df1, by="date") %>%
  rename("oil_price" = "dcoilwtico.y") %>%
  subset(select = -dcoilwtico.x)
```

### 3. EDA(Exploratory Data Analysis) by using ggplot
##### 3-1. holiday, store에 따른 sales의 차이 확인
```{r}
train_set %>%
  group_by(store_nbr, holiday) %>%
  summarize(sales_amt = sum(sales) / n()) %>%
  ggplot(aes(x=store_nbr, y=sales_amt, fill=holiday))+
  geom_bar(stat="identity", position = "dodge")+
  labs(title="Comparison of Sales between Weekdays and Holidays",)+
  theme_bw()+
  theme(legend.title = element_blank(),
        legend.position = c(0.2,0.9),
        plot.title = element_text(hjust = 0.5))+
  scale_fill_manual(values = c("skyblue", "lightpink"),
                    labels = c("weekday","holiday"))
  
# 헤맨 이유 : 그래프가 잘 그려지지 않았는데, 그 이유는 초반에 family를 기준으로 데이터를 삭제할 때 문제의 조건을 잘못 이해해서 너무 많이 삭제해서 그렇다! train_set을 다시 조정하니 결과값이 잘 나온다! (zero_family = 0인 것을 실수로 삭제해버렸음 ㅠ)
# holiday 변수도 범주형 변수 취급해주어야 함!
# scale_fill_manual은 기존에 데이터가 fill되어 있을 때 그 위에 새롭게 색을 입혀주는 것!

# 대부분주말에 판매량이 더 높게 나타나고, store별로 판매량의 차이도 크게 나타난다.
```

##### 3-2. store과 type의 연관성
```{r}
train_set %>%
  group_by(cluster, type) %>%
  summarize(sales_amt = sum(sales)) %>%
  ggplot(aes(x=cluster, y=type, size = sales_amt)) +
  geom_point(color="grey")+
  theme_bw()
```

##### 3-3. month와 wday에 따른 sales 차이
```{r}
library(gridExtra) #여러개의 plot을 한번에 표현할 수 있는 기능

plot1 <- train_set %>%
  group_by(month) %>%
  summarize(sales_sum = sum(sales)) %>%
  ggplot(aes(x=month, y=sales_sum, fill=month)) +
  geom_bar(stat = "identity", alpha = 0.3)+
  labs(title = "Monthly sales")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "none")
  

plot2 <- train_set %>%
  group_by(wday) %>%
  summarize(sales_sum = sum(sales)) %>%
  ggplot(aes(x=wday, y=sales_sum, fill=wday)) +
  geom_bar(stat = "identity", alpha = 0.3)+
  theme_classic()+
  labs(title = "Weekly sales")+
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "none")
  

grid.arrange(plot1, plot2, ncol = 2)

# 색 적용 방식) fill ="yellow" / "HEX컬러코드" / scale_fill_manual(색상선택) / scale_fill_brewer(미리 정제된 색) // 테두리의 경우 fill이 아닌 color로 수정한다!
# 7월과 12월에 유독 판매량이 증가하고, 주말의 판매량이 대체적으로 높게 나타난다.
  
```

##### 3-4. oil price와 sales의 상관관계, Pearson 상관계수도 구하기
```{r}
train_set %>%
  group_by(date, oil_price) %>% #date도 같이 group_by해줘야 함!
  summarize(sales_sum = sum(sales)) %>%
  ggplot(aes(x=sales_sum, y=oil_price))+
  geom_point(pch=19, color = "darkorange", alpha = 0.5)+
  theme_classic()
```


```{r}
train_sales_cor_set <- train_set %>%
  group_by(date, oil_price) %>% #date도 같이 group_by해줘야 함!
  summarize(sales_sum = sum(sales))

cor.test(train_sales_cor_set$sales_sum, train_sales_cor_set$oil_price, method = "pearson")
# -0.2정도의 약한 음의 상관관계를 지님
```

### 4. Time Series CV(Cross Validation,교차검증) : 과적합을 방지하는 방법 / 시계열인 만큼 데이터의 순서가 섞이면 안된다! Catboost 이용
##### 4-1. 모델링에 필요한 column만 남기기
```{r}
library(catboost)
library(Metrics)

# 열 이름을 가지고는 -c('열 이름') 이러한 방식으로 column을 제거할 수 없다!
tr <- subset(train_set, select = -c(date, id, oil_price, state, type, cluster))
```

##### 4-2. 데이터 프레임 만들고 catboost와 파라미터 설명
```{r}
result <- data.frame(learning_rate = c(0.10,0.01,0.10,0.01), iterations = c(50,50,100,100), rmse = c(NA, NA, NA, NA))
result
```

##### 4-3. time series cv를 위한 index list 생성성
```{r}
set.seed(3040)
tr_index = list(a = 1 : (nrow(tr)-26730*5),
                b = 1 : (nrow(tr)-26730*4),
                c = 1 : (nrow(tr)-26730*3),
                d = 1 : (nrow(tr)-26730*2),
                e = 1 : (nrow(tr)-26730*1))
val_index = list(a = (nrow(tr)-26730*5) : (nrow(tr)-26730*4),
                  b = (nrow(tr)-26730*4) : (nrow(tr)-26730*3),
                  c = (nrow(tr)-26730*3) : (nrow(tr)-26730*2),
                  d = (nrow(tr)-26730*2) : (nrow(tr)-26730*1),
                  e = (nrow(tr)-26730*1) : (nrow(tr)))

# 기본적인 가공을 해준 tr데이터에서 순서대로 일부 데이터들을 빼와서 train과 validation set으로 사용한다! -> 그래서 indexing을 할 수 있는 list를 만들어준 것이다!
```

##### 4-4. index을 활용한 시계열 교차검증 -> rmse 구하기 -> 이것을 result data에 저장하고 rmse가 가장 낮은 행 출력 / catboost.load_pool 이용해서 모델에 저합한 데이터로 변형

```{r}
train_x_data <- tr %>% select(-sales) #독립변수 저장
train_y_data <- tr$sales %>% as.matrix %>% as.integer #종속변수 저장(변수가 하나이기 때문에 이걸 matrix형태로 바꾸어주었다!)

#처음에 지정해 둔 사전 result df를 사용해서 해당 parameter마다 어떻게 rmse가 변화하는지 확인하기 위함!
#행의 수만큼 반복
for (k in 1:nrow(result)){ 
  param <- list(learning_rate = result$learning_rate[k],
                iterations = result$iterations[k], #각 행마다의 parameter를 사용
                loss_function = "RMSE") #계산하는 loss로 RMSE를 사용
  
  CV_rmse = NULL #계산될 rmse를 저장하기 위한 빈 리스트 만들기
  
  #train index수만큼 반복
  for (i in 1:length(tr_index)){ 
    CV_train_x <- train_x_data[tr_index[[i]]]
    CV_train_y <- train_y_data[tr_index[[i]]]
    CV_val_x <- train_x_data[val_index[[i]]]
    CV_val_y <- train_y_data[val_index[[i]]]
    #리스트는 괄호 두개[[]]를 써야 sub-list 안에 있는 값까지 접근할 수 있음! -> train과 val을 위한 값 추출
    
    CV_train_pool <- catboost.load_pool(data = CV_train_x,
                                        label = CV_train_y)
    CV_val_pool <- catboost.load_pool(data = CV_val_x,
                                      label = CV_val_y)
    #catboost모델에 적합시키기 위해 cat boost.load_pool로 모델에 적합한 형태로 변환해주는 작업(data와 label로 구분)
    
    CV_model <- catboost.train(CV_train_pool, params = param)
    #model에 집어 넣기 위한 형태변환까지 해주었으니, 이제 진짜 모델을 돌린다!
    
    CV_pred <- catboost.predict(CV_model, CV_val_pool)
    #model에 적합시킨 train_pool을 바탕으로 val_pool에 대한 prediction을 진행
    
    CV_rmse <- c(CV_rmse, rmse(CV_val_y, CV_pred))
    #prediction값과 실제 val값을 rmse를 통해 비교(예측값과 실제값의 차이, 손실, loss)
  }
  result[k,'rmse'] <- CV_rmse %>% mean()
  #result 행마다 rmse의 평균을 계산해서 보여준다
}

result
```


```{r}
result_min_rmse <- result[which.min(result[,'rmse']),]
result_min_rmse
```

### 5. 모델링과 예측
##### 5-1. test_set 전처리 진행
```{r}
te <- test_set %>%
  mutate(wday = wday(date, label = TRUE),
         year = year(date),
         month = month(date)) %>%
  filter(! store_nbr %in% c(52,22,42,21,29,20,18)) %>%
  filter(! family %in% c('MAGAZINES','HOME CARE','PET SUPPLIES','CELEBRATION','PLAYERS AND ELECTRONICS','LADIESWEAR','SCHOOL AND OFFICE SUPPLIES','BABY CARE','BOOKS')) %>%
  mutate(store_nbr = as.factor(store_nbr),
         family = as.factor(family),
         holiday = as.factor(holiday),
         city = as.factor(city),
         state = as.factor(state),
         type = as.factor(type),
         cluster = as.factor(cluster),
         wday = as.factor(wday),
         year = as.factor(year),
         month = as.factor(month)) %>%
  subset(select = -c(date, id, state, type, cluster))
```


##### 5-2. 도출한 최적의 parameter를 활용해 전체 train_set 적합, test 기간의 sales 예측
```{r}
best_param <- list(learning_rate = 0.1,
              iterations = 100,
              loss_function = "RMSE") #이전 적합의 과정에서 나온 param값 사용

final_rmse = NULL

x_train <- tr %>% select(-sales)
y_train <- tr$sales %>% as.matrix %>% as.integer
x_test <- te %>% select(-sales)
y_test <- te$sales %>% as.matrix %>% as.integer #진짜 찐!!!!! 데이터

train_pool <- catboost.load_pool(data = x_train,
                                 label = y_train)
test_pool <- catboost.load_pool(data = x_test,
                               label = y_test) #model에 대입하기 위해 형태 바꿔주는 pool

model <- catboost.train(train_pool, params = best_param) #model에 진짜 train_data랑 best_param 넣고 돌리기!

prediction <- catboost.predict(model, test_pool) #model을 통해 test_pool을 예측
prediction
```

##### 5-3. 예측값과 실제값의 rmse 구하기
```{r}
final_rmse <- rmse(y_test, prediction)
final_rmse
#실제 test의 y값과 예측값 간의 차이 구하기
```