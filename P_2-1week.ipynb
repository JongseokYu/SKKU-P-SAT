{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ca0ca2",
   "metadata": {},
   "source": [
    "# 주제분석 2주차 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a956d0",
   "metadata": {},
   "source": [
    "## Chaper 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756312c0",
   "metadata": {},
   "source": [
    "### 문제0. 기본세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd95bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pathlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b550c",
   "metadata": {},
   "source": [
    "### 문제1. 시드설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70406797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(17)\n",
    "seed = np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18976220",
   "metadata": {},
   "source": [
    "### 문제2. dog, cat 변수를 만들어 폴더에 들어있는 경로들을 리스트 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f9e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cat_dir = pathlib.Path('C:/Users/yjs49/Desktop/통계분석학회 P-SAT/패키지 방학 복습/2주차 패키지/training_set/cats')\n",
    "dog_dir = pathlib.Path('C:/Users/yjs49/Desktop/통계분석학회 P-SAT/패키지 방학 복습/2주차 패키지/training_set/dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2700096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "for i in cat_dir.iterdir():\n",
    "    cat.append(i)\n",
    "    \n",
    "dog = []\n",
    "for i in dog_dir.iterdir():\n",
    "    dog.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce94803",
   "metadata": {},
   "source": [
    "### 문제3. 저장한 리스트를 8:2로 나누고 train/test로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22be87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_train, cat_val = train_test_split(cat, test_size = 0.2, shuffle = True, random_state = seed)\n",
    "dog_train, dog_val = train_test_split(dog, test_size = 0.2, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d243a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cat_train + dog_train\n",
    "val = cat_val + dog_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dc48f",
   "metadata": {},
   "source": [
    "### 문제4. torchvision.transforms를 이용하여 이미지 데이터 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d22de",
   "metadata": {},
   "source": [
    "### 4-1. train 데이터셋 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab751c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128,128)), #사이즈 조정\n",
    "    transforms.RandomHorizontalFlip(), #이미지를 수직변환할 수 있게 하여 방향변화에 robust한 형태로 만들기\n",
    "    transforms.ToTensor() #PIL 형태의 이미지나 ndarray 를 PyTorch 가 이해할 수 있는 tensor 자료형으로 바꾸어 주는 역할\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4e87c",
   "metadata": {},
   "source": [
    "### 4-2. val 데이터셋 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002740c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf1daf",
   "metadata": {},
   "source": [
    "### 문제5. Dataset class 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3469cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#데이터의 양이 방대할 경우, 데이터를 한번에 불러오기 어렵기 때문에, 하나씩 불러서 쓰는 방식을 택하기 위해 Dcustomized된 ataset을 사용함\n",
    "#미니배치 학습, 데이터 셔플, 병렬 처리까지 간단하게 수행\n",
    "\n",
    "class Dataset(Dataset) :\n",
    "    \n",
    "    def __init__(self, data, transforms): #생성될 때 한번만 실행됨\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self): #데이터의 개수 \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index): #인덱스값을 기준으로 데이터셋에서 sample을 가져오고, 이를 변환하는 과정을 거침\n",
    "        image_path = self.data[index]\n",
    "        image = PIL.Image.open(image_path)\n",
    "        image_transformed = self.transforms(image)\n",
    "        \n",
    "        if \"cat\" in str(self.data[index]) :\n",
    "            label = 0\n",
    "        else :\n",
    "            label = 1\n",
    "            \n",
    "        return image_transformed, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad13c7a",
   "metadata": {},
   "source": [
    "### 6. 만든 Dataset class를 이용하여 train, val 데이터를 Dataset 형식으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6906b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data = train, transforms = train_transforms)\n",
    "val_dataset = Dataset(data = val, transforms = val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e7937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6404 1601\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e3136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9059, 0.9059, 0.9059,  ..., 0.9255, 0.9255, 0.9255],\n",
       "          [0.9059, 0.9098, 0.9020,  ..., 0.9255, 0.9255, 0.9255],\n",
       "          [0.9098, 0.9137, 0.5216,  ..., 0.5176, 0.9255, 0.9255],\n",
       "          ...,\n",
       "          [0.9255, 0.9176, 0.8000,  ..., 0.8039, 0.9255, 0.9255],\n",
       "          [0.9176, 0.9137, 0.9294,  ..., 0.9333, 0.9255, 0.9255],\n",
       "          [0.9255, 0.9255, 0.9255,  ..., 0.9216, 0.9216, 0.9255]],\n",
       " \n",
       "         [[0.9569, 0.9569, 0.9490,  ..., 0.9490, 0.9451, 0.9451],\n",
       "          [0.9569, 0.9569, 0.9451,  ..., 0.9490, 0.9451, 0.9451],\n",
       "          [0.9569, 0.9569, 0.5647,  ..., 0.5412, 0.9451, 0.9451],\n",
       "          ...,\n",
       "          [0.9451, 0.9373, 0.8196,  ..., 0.8275, 0.9451, 0.9451],\n",
       "          [0.9373, 0.9333, 0.9490,  ..., 0.9529, 0.9451, 0.9451],\n",
       "          [0.9451, 0.9451, 0.9451,  ..., 0.9412, 0.9412, 0.9451]],\n",
       " \n",
       "         [[0.9294, 0.9294, 0.9255,  ..., 0.9333, 0.9216, 0.9216],\n",
       "          [0.9294, 0.9294, 0.9216,  ..., 0.9333, 0.9255, 0.9216],\n",
       "          [0.9294, 0.9333, 0.5412,  ..., 0.5255, 0.9255, 0.9216],\n",
       "          ...,\n",
       "          [0.9294, 0.9216, 0.8039,  ..., 0.8118, 0.9216, 0.9216],\n",
       "          [0.9216, 0.9176, 0.9333,  ..., 0.9412, 0.9216, 0.9216],\n",
       "          [0.9255, 0.9255, 0.9255,  ..., 0.9216, 0.9176, 0.9216]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ad6eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3216, 0.1137, 0.0353,  ..., 0.5333, 0.5294, 0.5255],\n",
       "          [0.3725, 0.1647, 0.0627,  ..., 0.5333, 0.5216, 0.5255],\n",
       "          [0.3843, 0.1843, 0.0627,  ..., 0.5255, 0.5176, 0.5137],\n",
       "          ...,\n",
       "          [0.3137, 0.3490, 0.3765,  ..., 0.1647, 0.0863, 0.0706],\n",
       "          [0.2392, 0.2549, 0.2627,  ..., 0.2118, 0.1020, 0.0784],\n",
       "          [0.1804, 0.1725, 0.1804,  ..., 0.2039, 0.1059, 0.0667]],\n",
       " \n",
       "         [[0.2667, 0.0941, 0.0392,  ..., 0.4627, 0.4667, 0.4667],\n",
       "          [0.2980, 0.1255, 0.0549,  ..., 0.4667, 0.4627, 0.4745],\n",
       "          [0.2941, 0.1333, 0.0392,  ..., 0.4706, 0.4667, 0.4706],\n",
       "          ...,\n",
       "          [0.2510, 0.2863, 0.3176,  ..., 0.0275, 0.0275, 0.0314],\n",
       "          [0.1647, 0.1765, 0.1922,  ..., 0.0471, 0.0431, 0.0392],\n",
       "          [0.1098, 0.0980, 0.1098,  ..., 0.0353, 0.0471, 0.0314]],\n",
       " \n",
       "         [[0.3020, 0.1176, 0.0549,  ..., 0.4902, 0.4941, 0.4941],\n",
       "          [0.3333, 0.1490, 0.0706,  ..., 0.4902, 0.4824, 0.4902],\n",
       "          [0.3294, 0.1529, 0.0510,  ..., 0.4824, 0.4745, 0.4706],\n",
       "          ...,\n",
       "          [0.3490, 0.3765, 0.3961,  ..., 0.0941, 0.0667, 0.0706],\n",
       "          [0.2549, 0.2745, 0.2627,  ..., 0.1216, 0.0824, 0.0745],\n",
       "          [0.1765, 0.1765, 0.1647,  ..., 0.1137, 0.0863, 0.0627]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b79b1c",
   "metadata": {},
   "source": [
    "### 7. Dataset을 Dataloader로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeb831fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#batch형태로 만들어서 우리가 실제로 학습할 때 이용할 수 있게 형태를 만들어주는 라이브러리 : DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a016010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x190951c3940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1832654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x190951c3880>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1620c0",
   "metadata": {},
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75d1eb",
   "metadata": {},
   "source": [
    "### 1. CNN 모델을 class 형태로 만들어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40726ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() ## 기반 class를 초기화하고, 해당 class 속성을 cubclass가 스스로 받아오도록 함!\n",
    "        \n",
    "        ### Conv2d -> BathNorm -> ReLU -> Maxpool\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3), ###in_channels) 흑백이면 1, RGB면 3\n",
    "            nn.BatchNorm2d(16),\n",
    "            ### batch정규화 : 각 배치 단위 별로 데이터가 다양한 분포를 가지더라도 각 배치별로 평균과 분산을 이용해 정규화\n",
    "            ### batch parameter의 기준은 input size\n",
    "            nn.ReLU(),\n",
    "            ### 양수면 자기자신, 음수면 0을 반환 / 갈수록 기울기가 소실되는 시그모이드 개선(0~1사이의 값만 내보냄)\n",
    "            ### 가중치 업데이트 속도, 연산 속도가 매우 빠르고(함수가 간단), 기울기 소실(vanishing Gradient)문제가 발생하지 않음\n",
    "            ### feature가 발현될 가능성을 비선형적 그래프로 나타내주는 작업이 필요(non-linearity 부여)\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            ### pooling은 파라미터를 줄여 overfitting을 방지하고, 속도를 높이기 위한 방법\n",
    "            ### convolution layer를 resize하여 새로운 layer를 얻는 것, 특징을 뽑아내는 작업\n",
    "        )    \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))        \n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))        \n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.fc = nn.Linear(1024,2) #평탄화 작업, Convolution/Pooling 프로세스의 결과를 취하여 다음 결과와 이어질 수 있게 연결하는 역할\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        \n",
    "        x = x.reshape(-1,1024)\n",
    "        \n",
    "        x = self.fc(x) ### fc layer를 거친 값으로 반환\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f3ce9",
   "metadata": {},
   "source": [
    "### 2. 그래픽카드로 장치 설정 후, 모델 그래픽 카드에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b943a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b774f30",
   "metadata": {},
   "source": [
    "### 3. optimizer와 loss function 정의(모델 학습을 위해 최적화, 손실 함수가 필요함!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "918806c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) #learniing rate 설정\n",
    "### Adam : 모멘텀 최적화 + RMSProp / 모멘텀 최적화처럼 Gradient Descent을 따르고, RMSProp처럼 그레디언트 제곱의 지수 감소 평균을 따름\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "### softmax(classification score을 0~1 사이로 정규화, 모든 합이 1) + crossentropy\n",
    "### 정답 class에 해당하는 값에 대해서만 log 합 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61010f86",
   "metadata": {},
   "source": [
    "### 4. 2중 for문을 이용한 모델 학습, iteration 100번 지날 때마다 loss 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d1ebe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 loss:  0.2441\n",
      "Epoch : 2 loss:  0.2900\n",
      "Epoch : 3 loss:  0.1810\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19744/1661335451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 30\n",
    "\n",
    "for epoch in range(num_epoch) :\n",
    "    ### enumerate : index와 원소로 이루어진 tuple 생성 (index와 원소에 동시 접근해서 loop를 돌릴 수 있음)\n",
    "    for index, [image, label] in enumerate(train_dataloader) :\n",
    "        x = image.to(device)\n",
    "        y = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        \n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if index % 100 == 99:\n",
    "            print(f'Epoch : {epoch + 1} loss: {loss : .4f}')\n",
    "            \n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b7a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546c790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322656de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ec737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
